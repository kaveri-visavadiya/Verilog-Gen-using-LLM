# Verilog-Gen-using-LLM

This repository contains a Verilog dataset and (Kaggle hyperlinks to) Python scripts for inferring from and fine-tuning chat versions of open-source LLMs - [Gemma 2b](https://huggingface.co/google/gemma-2b-it), [Gemma 7b](https://huggingface.co/google/gemma-7b-it), [Llama 3 8b](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) and [Llama 2 7b](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) using common Hugging Face libraries. The codes are hosted on [Kaggle](https://www.kaggle.com/kaverivisavadiya/code). I contributed to this project as part of my summer project in June-July '24 under Prof. Joycee Mekie along with [Zaqi Momin}(https://www.linkedin.com/in/zaqimomin/) and [Mihir Agarwal](https://www.linkedin.com/in/mihir-agarwal-33b913188/) at IIT Gandhinagar.

## Dataset: 

For the experiments, the [NYU Verilog dataset](https://huggingface.co/datasets/shailja/Verilog_GitHub) available on Hugging Face was utilized to create a dataset containing around 8,000 synthesizable codes. This dataset forms the basis of subsequent analysis and experiments.

## Models: 

Open source models chosen are Gemma 2b, Gemma 7b, Llama 3 8b and Llama 2 7b. Due to memory and GPU limitations, the experiments were constrained to models with a reduced number of parameters and were further quantized when loaded. From these models, Llama 3 8b came closest to producing correct Verilog code and Gemma 2b was the worst at producing Verilog code.

Closed source models used for comparison are ChatGPT 3.5, ChatGPT 4o and Gemini. From these, ChatGPT 4o emerges as the model with the highest accuracy of correct Verilog generation and Gemini emerges as the least accurate.

## Inference:

Inference is the process of obtaining responses from a trained LLM model in response to a user's query or prompt. 
To see how well the LLMs performed on Verilog generation, we utilized a list of common digital circuit architectures ranging from simple (half adder, full adder, etc.) to complex designs (UART, FFT Module, etc.) and performed inference. This [doc](https://docs.google.com/document/d/1DIBSmYpYoAF7v6eufFmZG5RknWoPVNEoGSBiStYq4TQ/edit?usp=sharing) contains the Verilog codes generated by each model and tabulates their correctness on the specified architectures. 

The following Kaggle scripts perform inference on the NYU dataset. This was a preliminary approach to creating the dataset (with Verilog codes and their corresponding inferred descriptions) for fine-tuning the models.

[Llama 3 8b](https://www.kaggle.com/code/kaverivisavadiya/llama3-8bchat-4bit-verilog)

[Llama 2 7b](https://www.kaggle.com/code/kaverivisavadiya/llama2-7bchat-4bit-verilog)

[Gemma 7b](https://www.kaggle.com/code/kaverivisavadiya/gemma-7b-it-4bit-verilog)

[Gemma 2b](https://www.kaggle.com/code/kaverivisavadiya/gemma-2b-it-4bit-verilog)

## Fine-tuning: 

Fine-tuning involves adapting a pre-trained model to perform better on a specific task or dataset by updating its parameters through additional training. Supervised fine-tuning (SFT) specifically refers to this process being guided by labeled data, where the model learns to produce accurate outputs by comparing its predictions to known correct answers and adjusting its weights accordingly. In our case, we focused on enhancing the model's ability to generate Verilog code descriptions based on provided prompts.

After performing supervised fine-tuning on the curated dataset (as mentioned above, with 8k synthesizable codes and their corresponding inferred descriptions), Llama 3 8b has [comparable accuracy](https://docs.google.com/spreadsheets/d/1wyHop5TK97V94MMOT1RxCiLUFd4x7IRIaS6fG5pRgac/edit?usp=sharing) to ChatGPT 3.5 in Verilog code generation.

### Kaggle codes:

Fine-tuning:

[Llama 3 8b](https://www.kaggle.com/code/kaverivisavadiya/fine-tune-llama3-8b)

[Gemma 7b](https://www.kaggle.com/code/kaverivisavadiya/fine-tune-gemma-7b)

(For my reference) [Hugging Face account](https://huggingface.co/kaveri1184) for pushing test models and datasets. 
