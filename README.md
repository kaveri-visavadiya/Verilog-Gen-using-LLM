# Verilog-Gen-using-LLM

This repository contains a Verilog dataset and (Kaggle hyperlinks to) Python scripts for inferring from and fine-tuning chat versions of open-source LLMs - [Gemma 2b](https://huggingface.co/google/gemma-2b-it), [Gemma 7b](https://huggingface.co/google/gemma-7b-it), [Llama 3 8b](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct) and [Llama 2 7b](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) using common Hugging Face libraries. The codes are hosted on [Kaggle](https://www.kaggle.com/kaverivisavadiya/code). This is an ongoing project and I started contributing to it as part of my summer project in June-July '24 under Prof. Joycee Mekie at IIT Gandhinagar.

## Dataset: 

For the experiments, the [NYU Verilog dataset](https://huggingface.co/datasets/shailja/Verilog_GitHub) available on Hugging Face was utilized to create a dataset containing around 8,000 synthesizable codes. This dataset forms the basis of subsequent analysis and experiments.

## Models: 

Open source models chosen are Gemma 2b, Gemma 7b, Llama 3 8b and Llama 2 7b. Due to memory and GPU limitations, the experiments were constrained to models with a reduced number of parameters and were further quantized when loaded. From these models, Llama 3 8b came closest to producing correct Verilog code and Gemma 2b was the worst at producing Verilog code.
Closed source models used for comparison are ChatGPT 3.5, ChatGPT 4o and Gemini. From these, ChatGPT 4o emerges as the model with the highest accuracy of correct Verilog generation and Gemini emerges as the least accurate.

## Inference:

Inference is the process of obtaining responses from a trained LLM model in response to a user's query or prompt. 
To see how well the LLMs performed on Verilog generation, we utilized a list of common digital circuit architectures ranging from simple (half adder, full adder, etc.) to complex designs (UART, FFT Module, etc.) and performed inference. This [doc](https://docs.google.com/document/d/1DIBSmYpYoAF7v6eufFmZG5RknWoPVNEoGSBiStYq4TQ/edit?usp=sharing) contains the Verilog codes generated by each model and tabulates their correctness on the specified architectures. 

## Fine-tuning: 

Fine-tuning involves adapting a pre-trained model to perform better on a specific task or dataset by updating its parameters through additional training. In our case, we focused on enhancing the model's ability to generate Verilog code descriptions based on provided prompts. Supervised fine-tuning (SFT) specifically refers to this process being guided by labeled data, where the model learns to produce accurate outputs by comparing its predictions to known correct answers and adjusting its weights accordingly. After fine-tuning on the curated dataset, Llama 3 8b has [comparable accuracy](https://docs.google.com/spreadsheets/d/1rcISU2mhBm3E-Ebwqjsnpcr4wumSnScwCmrlMpcCnAo/edit?usp=sharing) to ChatGPT 3.5 in Verilog code generation.

### Kaggle codes:

Fine-tuning:
[Llama 3 8b](https://www.kaggle.com/code/kaverivisavadiya/fine-tune-llama3-8b)
[Gemma 7b](https://www.kaggle.com/code/kaverivisavadiya/fine-tune-gemma-7b)

(For my reference) [Hugging Face account](https://huggingface.co/kaveri1184) for pushing test models and datasets. 
